{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4b5181-31a0-4dcd-bb74-7fc8cdb4bfaa",
   "metadata": {},
   "source": [
    "# NLP - Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf7e84-a4cd-483a-bc9f-548fd24d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5317bb5-9ed9-4813-b822-17ecdce42095",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://insights.blackcoffer.com/ml-and-ai-based-insurance-premium-model-to-predict-premium-to-be-charged-by-the-insurance-company/\"\n",
    "\n",
    "\n",
    "data = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea4f45-a9de-4cb3-adec-266a115ad124",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a1550-5458-4c45-84d6-393ed57011a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b7bfb-5ea4-409c-b9fb-184572da4855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25eb179f-151d-4174-9ff2-ef5e776401a7",
   "metadata": {},
   "source": [
    "## USing BEautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eeace9-7a37-40f5-8e37-26d4b0c9cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://insights.blackcoffer.com/ml-and-ai-based-insurance-premium-model-to-predict-premium-to-be-charged-by-the-insurance-company/\"\n",
    "\n",
    "\n",
    "data = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(data.content.decode('utf8'), 'html5lib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771a730-c090-437c-8bb6-c197a954f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02328aed-52c8-49af-bf42-b339c96744a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(soup.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220abce5-7342-46b3-baa2-4d97eb07b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('article')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b8db4-d237-4a9e-ae34-00f69ca7ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  class=\"entry-title\"> - title\n",
    "\n",
    "# <div class=\"td-post-content tagdiv-type\">\n",
    "\n",
    "title_article = title.find('h1', attrs={'class': 'entry-title'})\n",
    "title_article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff2faf-0e81-4c3f-a5be-88490cab1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_article = title.find('div', attrs= {'class': 'td-post-content tagdiv-type'})\n",
    "\n",
    "dummy = main_article.text.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65adefed-4e4f-48ff-926d-a3c93400ac83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83dddab-7f15-4df8-a471-20b7df9654ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = list(filter(None, dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc22f00-d53a-4f6c-82fc-bbb87a60fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = '\\n'.join(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ea1ad-ba25-48e8-b29d-0cf911d8072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\n",
    "\n",
    "content = content + title_article.text + \"\\n\" + dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1e059-92da-41c0-9443-e0f79a562b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d38fea-d467-4ca9-b57c-1370d633b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## article in a text file with URL_ID as its file name.\n",
    "\n",
    "import io\n",
    "\n",
    "file_name = 'bctech2011.txt'\n",
    "\n",
    "with io.open(file_name, 'w', newline= '', encoding= 'utf8') as f:\n",
    "    f.write(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252d221-18ed-4431-b786-e5528927ee3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_Array = []\n",
    "\n",
    "data_Array = list(content.lower().split())\n",
    "\n",
    "data_Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6c8e3-1921-4618-aa78-83af0bb5f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_name_list = ['Auditor', 'Currencies', 'DatesandNumbers', 'Generic', 'GenericLong', 'Geographic', 'Names']\n",
    "stop_Words_arrray_name = ['stop_words_Auditor',\n",
    "'stop_words_Currencies',\n",
    "'stop_words_DatesandNumbers',\n",
    "'stop_words_Generic',\n",
    "'stop_words_GenericLong',\n",
    "'stop_words_Geographic',\n",
    "'stop_words_Names']\n",
    "\n",
    "stop_words_Auditor = []\n",
    "stop_words_Currencies = []\n",
    "stop_words_DatesandNumbers = []\n",
    "stop_words_Generic = []\n",
    "stop_words_GenericLong = []\n",
    "stop_words_Geographic = []\n",
    "stop_words_Names = []\n",
    "\n",
    "stop_word_array_path = []\n",
    "path = \"20211030 Test Assignment\\StopWords\\StopWords_\"\n",
    "\n",
    "\n",
    "for list in stop_words_name_list:\n",
    "    stop_word_array_path.append(path + list + '.txt')\n",
    "\n",
    "for idx, word_paths in enumerate(stop_word_array_path):\n",
    "    \"\"\"stop_path_name = stop_words_name_list[idx] \n",
    "    stop_path_name = []\n",
    "    #print(word_paths) \"\"\"\n",
    "    with io.open(word_paths, 'r') as f:\n",
    "        globals()[stop_Words_arrray_name[idx]] = [ i.replace('\\n', '').lower() for i in f.readlines()]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75556c37-6892-4ef8-be6f-c6724118badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_Auditor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b05ff3-8f7f-4fd4-8964-5e44b018e3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words_Currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebfa0f-c0b2-4318-80f2-63697bbd863a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words_DatesandNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d34bfb-0e44-478a-9520-76dfbdf8c8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words_Generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d1e23-fd63-4836-baaa-0f8b95edf19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words_GenericLong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614df3cf-baf0-4f6b-8318-ade82baa9ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words_Geographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7d788-a6a9-484f-b84a-bf8818ba8335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words_Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08227540-80d5-4ea8-97c7-4955c692992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_Currencies_Edited = []\n",
    "\n",
    "for i in stop_words_Currencies:\n",
    "    stop_words_Currencies_Edited.append(i.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8af89-67f5-4982-804a-2d6d5b32415c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words_Currencies_Edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5527c2b-f950-43dd-9de5-f7245b40e165",
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in stop_words_Currencies:\n",
    "     if i.find('birr') == 0:\n",
    "         print(i)\n",
    "     else:\n",
    "         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ec46c-93b0-41bf-bb44-4c02ce48cb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41667a97-5e01-4c56-a36c-598514445ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stop_word(data_array):\n",
    "\n",
    "    stop_word_inFILE = [] # find the stop words in file (data_Array)\n",
    "    withput_stop_word_array = [] # cleaned array without stop words\n",
    "    \n",
    "    \"\"\"\n",
    "    for arr in stop_Words_arrray_name:\n",
    "        for i in globals()[arr]:\n",
    "            print(i)\n",
    "    \n",
    "    \"\"\"\n",
    "    for ori_word in data_array:         # walk thogh original array\n",
    "        if ori_word not in stop_word_inFILE:  # did not repeat for same stop word in clean_array\n",
    "            for arr in stop_Words_arrray_name:  # walk though one array\n",
    "                if ori_word in globals()[arr]:   # if any original_array in stop words add it to cleaned_data_array\n",
    "                    stop_word_inFILE.append(ori_word) \n",
    "                    \n",
    "                    break\n",
    "    return stop_word_inFILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f972e-0c99-4151-9c89-1e7840709894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_stop_word(data_Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fca92-b9ff-4111-a920-c61562d476c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stop_word_inFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362a661-24c2-4ae7-a9c1-fdfd2c9eca6a",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c0d897-674c-419b-a2b4-6f0ca01df1af",
   "metadata": {},
   "source": [
    "### cleaning using stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6fbe8-e79c-428f-b374-05b4ddc68dd6",
   "metadata": {},
   "source": [
    "### cleaning using stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c43d1-2d0f-41a1-af67-d17f3d42c6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebc317-562b-4e94-bcc0-5ce780b7278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "withput_stop_word_array = [i for i in data_Array if i not in stop_word_inFILE] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4880ac5-f641-4d46-8f33-98c34a9dfeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## master dictionary\n",
    "\n",
    "master_dict = ['positive', 'negative']\n",
    "master_path  = []\n",
    "\n",
    "\n",
    "for i in master_dict:\n",
    "    master_path.append('20211030 Test Assignment\\MasterDictionary\\\\' + i + '-words.txt')\n",
    "\n",
    "for idx,path in enumerate(master_path):\n",
    "    with io.open(path) as f:\n",
    "        globals()[master_dict[idx]] = [ i.lower().replace('\\n','') for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34bdbd-c543-437e-b77c-9679aab5b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17913a47-2146-434c-a7d6-8995f3db48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b987a-9bca-4708-aa14-8ee8d605f76a",
   "metadata": {},
   "source": [
    "## NLTK tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495f318-1609-4eb6-98a9-622abc690480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "word_token = nltk.tokenize.word_tokenize(content.lower())\n",
    "sentence_token = nltk.LineTokenizer(blanklines='keep').tokenize(content.lower())  # line tokenize\n",
    "\n",
    "nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "print(sentence_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9aac8-1adb-48c3-84ff-e3867ac39079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ i for i in remove_stop_word(word_token) if i not in remove_stop_word(data_Array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa9169-12fd-403d-9695-2810f6a2ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_wordds = remove_stop_word(word_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652283c6-8a36-4b2d-a09d-83e56c40a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(word_token_st_removed[1780])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f5453-343e-4075-8ec4-7929f707e847",
   "metadata": {},
   "source": [
    "## positive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285f2dc-f918-4789-bff1-c852f5595358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "punctuation =  [i for i in punctuation]\n",
    "punctuation.append('’')\n",
    "\n",
    "\n",
    "positive_score = 0\n",
    "negative_score = 0\n",
    "\n",
    "\n",
    "word_token_st_removed = [i for i in word_token if i not in stop_wordds and i not in nltk_stop_words  and i not in punctuation]\n",
    "\n",
    "for word in  word_token_st_removed:\n",
    "    if word in positive:\n",
    "        positive_score = positive_score+ 1\n",
    "    elif word in negative:\n",
    "        negative_score = negative_score -1\n",
    "\n",
    "negative_score = abs(negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649ca31-7ff0-4d02-b9c0-5bb11a4f10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25218e17-04b6-4567-baeb-41b0b61959a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e6e6f-bd90-4f27-9a9d-97cf1d8724b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word = [i for i in word_token_st_removed if len(i)==1]\n",
    "single_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215e33d-dd40-4344-8103-ef56070c2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stop words using nltk\n",
    "\n",
    "print( [i for i in word_token_st_removed if i in nltk.corpus.stopwords.words('english')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275786d7-21b6-4bb6-ae4d-583a4cfcb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_token_st_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab348801-6823-498f-a0d0-d46a07116cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token_st_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33478499-73ab-4777-bce0-7b4ffc71e13f",
   "metadata": {},
   "source": [
    "## Polarity score\n",
    "\n",
    "- Polarity Score\n",
    "  \n",
    " **(Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed0258-251a-4eaa-8a1f-3e44a19d59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_Score = (positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "\n",
    "polarity_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88bd62-b157-4a84-a0b1-3886e6402fc6",
   "metadata": {},
   "source": [
    "## Sujectivity score\n",
    "\n",
    " - Subjectivity Score\n",
    "   \n",
    "**(Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608074a-7308-457f-89b0-5c46fc585579",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_score = (positive_score + negative_score) / ((len(word_token_st_removed)) +  0.000001)\n",
    "subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac489680-c768-41f3-b98d-b7de143e7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_token_st_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb60e6-3838-4fbe-a807-1efdd857cde9",
   "metadata": {},
   "source": [
    "## Analysis of Readability\n",
    " -  \n",
    "Analysis of Readability is calculated using the Gunning Fox index formula described below\n",
    " -  \r\n",
    "Average Sentence Length `= the number of words / the number of sentenc`\n",
    " -  s\r\n",
    "Percentage of Complex words` = the number of complex words / the number of wo   `\n",
    " -  s \r\n",
    "Fog Inde`x = 0.4 * (Average Sentence Length + Percentage of Complex wo`rds)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454057d-14fe-490a-9994-2c0d7864c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Average_Sentence_Length = len(word_token_st_removed) / len(sentence_token)\n",
    "Average_Sentence_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c0116-5a43-40b9-a087-016d49e0ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "complex_word = [ i for i in word_token_st_removed if len(i) >2]\n",
    "\n",
    "Percentage_of_Complex_words = len(complex_word) / len(word_token_st_removed)\n",
    "print(Percentage_of_Complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d69208-aeae-40b4-a66a-d23be6a961b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fog_inde = 0.4 * (Average_Sentence_Length + Percentage_of_Complex_words)\n",
    "fog_inde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42cd62-5629-4366-8241-ee764bdc10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = '1'\n",
    "re.sub(r'\\d+','', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e506aa1-10d6-466f-8964-4a7489f72cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = len(word_token_st_removed)\n",
    "word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc6bf8-2b0a-44b0-bc0f-221c9b602f07",
   "metadata": {},
   "source": [
    "## syllable tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767ac64-c7a7-485d-aafd-0880b2338932",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable  = nltk.SyllableTokenizer()\n",
    "syllable_words = [ syllable.tokenize(i) for i in word_token_st_removed]\n",
    "\n",
    "vowel_pattern = re.compile(r'[aeiou]')\n",
    "\n",
    "vowel_count_syllable = [ j for i in syllable_words for j in i if len(vowel_pattern.findall(j)) > 0]\n",
    "len(vowel_count_syllable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f30bc5-44d5-4bd3-a7a8-215aca7991ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Syllable_per_word = len(vowel_count_syllable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a293f8e-3d32-4ad0-8493-f41717dd9019",
   "metadata": {},
   "source": [
    "## Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd841bc-08d8-4a07-9c67-e3ff6e6658a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun = ['i', 'we', 'my', 'ours', 'us'] # not include us so that it won't affect \"US\"\n",
    "\n",
    "pronoun_pattern = re.compile(r\"\\b{?:i| we | my | ours | us}\\b\")\n",
    "matched = pronoun_pattern.findall(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1ecc5-2b77-48e9-8c8f-0f9da4d15b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_pronoun_count = len(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5236ab8-e419-4faf-ae6c-6d0e47d6701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_pronoun_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e7927-37f3-489f-b111-f1412f3896c9",
   "metadata": {},
   "source": [
    "## Average word length\n",
    "\n",
    "Average Word Length is calculated by the formula: \r",
    " - **\n",
    "Sum of the total number of characters in each word/Total number of word**s\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8bdf4-9db3-40b9-a556-767e188fbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "charecter_count = len([j for i in word_token_st_removed for j in i])\n",
    "\n",
    "Average_word_lenght = charecter_count / len(word_token_st_removed)\n",
    "Average_word_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801b7cd-fb00-494d-93d7-b5ddbf6a7c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
